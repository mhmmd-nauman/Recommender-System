 propose approach problem searching space  stochastic controllers Markov decision process (MDP) partially  observable Markov decision process (POMDP).  authors, approach based searching parameterized families  policies (for example, gradient descent) optimize solution qual-  ity. However, trying estimate values derivatives  policy directly, indirectly estimates proba-  bility densities policy induces states points  time. enables algorithms exploit techniques  efficient robust approximate density propagation stochastic sys-  tems. show techniques applied deterministic  propagation schemes (where MDP's dynamics explicitly  compact form,) stochastic propagation schemes (where  access generative model, simulator, MDP). present  empirical results variants complex problems. 