 AdaBoost ensemble methods successfully ap-  plied number classification tasks, seemingly defying prob-  lems overfitting. AdaBoost performs gradient descent error  function respect margin, asymptotically concentrating  patterns hardest learn. noisy prob-  lems, however, disadvantageous. Indeed, theoretical  analysis shown margin distribution, opposed  minimal margin, plays crucial role understanding phe-  nomenon. Loosely speaking, outliers tolerated  benefit substantially increasing margin  remaining points. propose boosting algorithm al-  lows possibility pre-specified fraction points lie  margin area wrong side decision boundary. 