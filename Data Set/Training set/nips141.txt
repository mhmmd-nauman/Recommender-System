 consider problem reliably choosing near-best strategy  restricted class strategies II partially observable Markov deci-  sion process (POMDP). assume ability simulate  POMDP, study called sample complexity --  is, amount data generate POMDP order  choose strategy. prove upper bounds sample com-  plexity showing that, infinitely large arbitrarily complex  POMDPs, amount data needed finite, depends  linearly complexity restricted strategy class II, expo-  nentially horizon time. dependence eased  variety ways, including application gradient local search  algorithms. measure complexity generalizes classical super-  vised learning notion VC dimension settings reinforcement  learning planning. 