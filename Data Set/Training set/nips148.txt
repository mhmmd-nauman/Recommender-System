 problem reinforcement learning non-Markov environment  explored dynamic Bayesian network, conditional indepen-  dence assumptions random variables compactly represented  network parameters. parameters learned on-line, approx-  imations perform inference compute optimal  function. relative effects inference function approxi-  mations quality final policy investigated, learning  solve moderately difficult driving task. function approx-  imations, linear quadratic, found perform similarly,  quadratic model sensitive initialization. performed be-  low level human performance task. dynamic Bayesian  network performed comparably model localist hidden  representation, requiring exponentially fewer parameters. 