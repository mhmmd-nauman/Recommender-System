 problem developing policies partially observable Markov  decision problems (POMDPs) remains challenging ar-  eas research stochastic planning. line research area  involves reinforcement learning belief states, probabil-  ity distributions underlying model states. promis-  ing method small problems, application limited in-  tractability computing representing full belief large prob-  lems. Recent shows that, settings, maintain  approximate belief state, fairly close true belief state.  particular, success shown approximate belief states  marginalize correlations variables. paper,  investigate methods full belief reinforcement learning  method reinforcement learning factored approximate  belief states. compare performance algorithms  well-known problem literature. results demonstrate im-  portance approximate belief representations large problems. 