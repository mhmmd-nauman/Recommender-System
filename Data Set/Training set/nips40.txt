 Gaussian mixtures (or so-called radial basis function networks)  density estimation provide natural counterpart sigmoidal neu-  ral networks function fitting approximation. cases,  give simple expressions iterative improve-  ment performance components network introduced  time. particular, mixture density estimation show  k-component mixture estimated maximum likelihood (or  iterative likelihood improvement introduce) achieves  log-likelihood order 1/k log-likelihood achievable  convex combination. Consequences approximation es-  timation Kullback-Leibler risk given. Minimum  Description Length principle selects optimal number compo-  nents minimizes risk bound. 