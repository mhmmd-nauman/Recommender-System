 Recently, sample complexity bounds derived problems in-  volving linear functions neural networks support vector ma-  chines. paper, extend theoretical results area  deriving dimensional independent covering number bounds regular-  ized linear functions regularization conditions. show  bounds lead class methods training linear clas-  sifiers similar theoretical advantages support vector machine.  Furthermore, present theoretical analysis meth-  ods asymptotic statistical point view. technique  description large sample behaviors algorithms. 