   Optimizing hadoop parameter settings gene expression programming guided PSO.   Hadoop MapReduce major computing technology support big data analytics. Hadoop framework 190 configuration parameters, significant effect performance Hadoop job. Manually tuning optimum optimum values parameters challenging task consuming process. paper optimizes performance Hadoop automatically tuning configuration parameter settings. proposed employs gene expression programming technique build objective function based historical job running records, represents correlation Hadoop configuration parameters. employs particle swarm optimization technique, makes objective function search optimal optimal parameter settings. Experimental results show proposed enhances performance Hadoop significantly compared default settings. Moreover, outperforms rule-of-thumb settings Starfish model Hadoop performance optimization. Hadoop Performance Modeling Job Estimation Resource Provisioning.  MapReduce major computing model data intensive applications. Hadoop, open source implementation MapReduce, adopted increasingly growing user community. Cloud computing service providers Amazon EC2 Cloud offer opportunities Hadoop users lease amount resources pay use. However, key challenge cloud service providers resource provisioning mechanism satisfy user jobs deadline requirements. Currently, solely user's responsibility estimate required amount resources running job cloud. paper presents Hadoop job performance model accurately estimates job completion provisions required amount resources job completed deadline. proposed model builds historical job execution records employs Locally Weighted Linear Regression (LWLR) technique estimate execution job. Furthermore, employs Lagrange Multipliers technique resource provisioning satisfy jobs deadline requirements. proposed model initially evaluated in-house Hadoop cluster subsequently evaluated Amazon EC2 Cloud. Experimental results show accuracy proposed model job execution estimation range 94.97 95.51 percent, jobs completed required deadlines resource provisioning scheme proposed model.  Hadoop performance modeling job optimization big data analytics.   Big data received momentum academia industry. MapReduce model emerged major computing model support big data analytics. Hadoop, open source implementation MapReduce model, widely community. Cloud service providers Amazon EC2 cloud supported Hadoop user applications. However, key challenge cloud service providers resource provisioning mechanism satisfy user jobs deadline requirements. Currently, solely user responsibility estimate require amount resources job running public cloud. thesis presents Hadoop performance model accurately estimates execution duration job provisions required amount resources job completed deadline. proposed model employs Locally Weighted Linear Regression (LWLR) model estimate execution job Lagrange Multiplier technique resource provisioning satisfy user job deadline. performance propose model extensively evaluated in-house Hadoop cluster Amazon EC2 Cloud. Experimental results show proposed model highly accurate job execution estimation jobs completed required deadlines resource provisioning scheme proposed model. addition, Hadoop framework 190 configuration parameters significant effects performance Hadoop job. Manually setting optimum values parameters challenging task consuming process. thesis presents optimization works enhances performance Hadoop automatically tuning parameter values. employs Gene Expression Programming (GEP) technique build objective function represents performance job correlation configuration parameters. purpose optimization, Particle Swarm Optimization (PSO) employed find automatically optimal optimal configuration settings. performance proposed intensively evaluated Hadoop cluster experimental results show proposed enhances performance Hadoop significantly compared default settings.  Parallel Detrended Fluctuation Analysis Fast Event Detection Massive PMU Data.   Phasor measurement units (PMUs) rapidly deployed power grids due high sampling rates synchronized measurements. devices high data reporting rates present major computational challenges requirement process potentially massive volumes data, addition issues surrounding data storage. Fast algorithms capable processing massive volumes data required field power systems. paper presents parallel detrended fluctuation analysis (PDFA) approach fast event detection massive volumes PMU data, taking advantage cluster computing platform. PDFA algorithm evaluated data installed PMUs transmission system Britain aspects speedup, scalability, accuracy. speedup PDFA computation initially analyzed Amdahl's Law. revision law proposed, suggesting enhancements capability analyze performance gain computation parallelizing data intensive applications cluster computing environment.  MapReduce Based Distributed LSI Scalable Information Retrieval.  Latent Semantic Indexing (LSI) widely information retrieval due efficiency solving problems polysemy synonymy. However, LSI notably computationally intensive process computing complexities singular decomposition filtering operations involved process. paper presents MR-LSI, MapReduce based distributed LSI algorithm scalable information retrieval. performance MR-LSI evaluated small scale experimental cluster environment, subsequently evaluated large scale simulation environments. partitioning dataset smaller subsets optimizing partitioned subsets cluster computing nodes, overhead MR-LSI algorithm reduced significantly maintaining high level accuracy retrieving documents user interest. genetic algorithm based load balancing scheme designed optimize performance MR-LSI heterogeneous computing environments computing nodes varied resources.  Big data analytics PMU measurements.   Phasor Measurement Units (PMUs) rapidly deployed power grids due high sampling rates. PMUs offer current accurate visibility power grids traditional SCADA systems. However, high sampling rates PMUs bring major challenges need addressed fully benefit PMU measurements. hand, transient events captured PMU measurements negatively impact performance steady analysis. hand, processing high volumes PMU data timely manner poses challenge computation. paper presents PDFA, parallel detrended fluctuation analysis approach fast detection transient events massive PMU measurements utilizing computer cluster. performance PDFA evaluated aspects speedup, scalability accuracy comparison standalone DFA approach.  Data locality Hadoop cluster systems.   MapReduce major programming model supports distributed parallel processing large-scale data-intensive applications Web data mining, network traffic analysis, machine learning scientific simulation. Hadoop popular open-source implementation MapReduce programming model. Hadoop, input files divided data blocks blocks distributed nodes cluster. efficiently process data blocks, Hadoop provide efficient scheduling mechanism enhancing performance system shared cluster environment. Hadoop scheduling mainly caused data locality issues due limited network bandwidth. introducing scheduling issues regarding data locality, paper review data locality aware scheduling algorithms handling data locality issues. addition, paper evaluating features, strength, weakness provided guidelines improve scheduling algorithms. 