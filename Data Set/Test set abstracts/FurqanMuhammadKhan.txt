  Multi-shot Person Re-Identification Part Appearance Mixture. Appearance based person re-identification real-world video surveillance systems challenging problem reasons, including ineptness existing low level features significant viewpoint, illumination, camera characteristic robustly describe person's appearance. approach handle appearance variability learn similarity metrics ranking functions implicitly model appearance transformation cameras camera pair, group, system. alternative, paper follows, fundamental approach improving appearance descriptors, called signatures, cater high appearance variance occlusions. signature representation multi-shot person reidentification presented paper multiple appearance models, describing appearance probability distribution low-level feature portion individual's body. Combined metric learning, rank-1 recognition rates 92:5% 79:5% achieved PRID2011 [12] iLIDS-VID [34] datasets, respectively. Identifying Persons Interest CCTV Camera Networks.  Computational Fusion Multi-View Multi-Illumination Imaging.  Unsupervised data association metric learning context multi-shot person re-identification.  Appearance based person re-identification challenging task, specially due difficulty capturing high intra-person appearance variance cameras inter-person similarity high. Metric learning address deficiency low-level features learning view specific re-identification models. models acquired supervised algorithm. practical real-world surveillance systems annotation effort view dependent. paper, propose strategy automatically generate labels person tracks learn similarity metric multi-shot person re-identification task. demonstrate multiple challenging datasets proposed labeling strategy significantly improves performance baseline methods extent improvement comparable manual annotations context KISSME algorithm  Person Re-identification Real-world Surveillance Systems.  Appearance based person re-identification real-world video surveillance system non-overlapping camera views challenging problem reasons. Current state-of-the-art methods address problem relying supervised learning similarity metrics ranking functions implicitly model appearance transformation cameras camera pair, group, system. requires considerable human effort annotate data. Furthermore, learned models camera specific transferable set cameras another. Therefore, annotation process required network expansion camera replacement, strongly limits applicability. Alternatively, propose modeling approach harness complementary appearance information supervised learning significantly outperforms current state-of-the-art unsupervised methods multiple benchmark datasets. Leveraging Mutual Information Local Descriptions: Local Binary Patterns Image.  Local image descriptors provide robust descriptions image localities. geometric arrangement additional information image describe, fact employing wide slew tasks image registration scene classification. premise descriptor quality assessed terms expressiveness image content, investigate additional geometric information task recovering image local descriptors. paper Local Binary Patterns, operator nested dense geometry, study additional information form constraints pixels dictates intensity estimated pixel. determine constraints propagate regional extrema regions observe constraint class, intensity regionâ€™s pixels influences others. build directed constraint graph pixel nodes arcs graph strongly k-consistent, propagate intensity estimates extremum nodes. Evaluations run SIPI texture BSD500 datasets. estimates preserve local structure image, shown Mean Absolute Error 15%15% 18%18% Structural Texture SIMilarity 92%92% datasets, addition observing 100%100% constraint satisfaction. Conditional Bayesian networks action detection. task understanding video content seen interest computer vision community increase camera based surveillance grocery stores, airports, train stations, etc. makes scene (objects) happens scene (actions) important dimensions video understanding. work, aim identify actions objects video, however, focus objects human interacts. videos multiple actions taking place possibly overlapping intervals. system recognize actions high intra-class variance performed complex environments objects types, sizes shapes. produce structured descriptions videos output. descriptions identify subject, object, verb interval activity recognized. Simultaneous inference activity, pose object.  Human movements important cues recognizing human actions, captured explicit modeling tracking actor space-time low-level features. However, relying solely human dynamics discriminate actions similar human dynamics, smoking drinking, irrespective modeling method. Object perception plays important role cases. Conversely, human movements indicative type object action. processes object perception action understanding independent. Consequently, action recognition improves human movements object perception conjunction. Therefore, propose probabilistic approach simultaneously infer action performed, object poses actor through. joint inference framework discriminate actions objects similar lack discriminative features. Multiple pose context trees estimating human pose object context.  address problem estimating pose static image human performing action involve interaction scene objects. scenarios, pose estimated accurately knowledge scene objects. Previous approaches contextual information. propose Pose Context trees jointly model human pose object accurate efficient inference nature interaction known. estimate pose image, present Bayesian framework infers optimal pose-object pair maximizing likelihood multiple pose context trees interactions. evaluate approach dataset 65 images, show joint inference pose context higher pose accuracy. 